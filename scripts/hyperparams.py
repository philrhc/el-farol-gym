e_greedy_optimal = {
    "learning_rate": 1,  # Reward multiplier
    "retention_rate": 0.02006827976496192,  # Forget some past experience
    "initial_epsilon": 0.5,  # Exploration probability
    "epsilon_decay": 0.00698608772471109,  # Exploration reduction over time
    "final_epsilon": 0.17041582725849416  # Final exploration probability
}

erev_roth_optimal = {
    "learning_rate":0.001,
    "phi":0.4028566874373059,
    "epsilon":0.003955266345682853,
    "retention_rate":1
}