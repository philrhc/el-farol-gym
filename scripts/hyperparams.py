e_greedy_optimal = {
    "learning_rate": 0.5,  # Reward multiplier
    "retention_rate": 0.8,  # Forget some past experience
    "initial_epsilon": 0.5,  # Exploration probability
    "epsilon_decay": 0.001,  # Exploration reduction over time
    "final_epsilon": 0.01  # Final exploration probability
}

erev_roth_optimal = {
    "learning_rate":0.001,
    "phi":0.4028566874373059,
    "epsilon":0.003955266345682853,
    "retention_rate":1
}